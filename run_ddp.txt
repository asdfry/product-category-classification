python -m torch.distributed.launch --nproc_per_node=3 --nnodes=1 --node_rank=0 --master_port=3663 train_lstm_temp_ddp.py
